{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 처리 딥러닝\n",
    "# Attention\n",
    "- https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3\n",
    "<img src='https://miro.medium.com/max/700/1*qN2Pj5J4VqAFf7dsA2dHpA.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://1.bp.blogspot.com/-AVGK0ApREtk/WaiAuzddKVI/AAAAAAAAB_A/WPV5ropBU-cxrcMpqJBFHg73K9NX4vywwCLcBGAs/s640/image2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq 모델에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc = np.random.randn(2,5,3).astype(np.float32) # np.float32\n",
    "X_dec = np.random.randn(2,4,3).astype(np.float32) # np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_enc = keras.layers.LSTM(3, return_sequences=True, return_state=True)\n",
    "lstm_dec = keras.layers.LSTM(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 5, 3]), TensorShape([2, 3]), TensorShape([2, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, h, c = lstm_enc(X_enc)\n",
    "\n",
    "y.shape, h.shape, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- attention 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = keras.layers.Dense(3) # 인코더의 출력값(y)에 곱해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = tf.matmul(X_dec, W(y), transpose_b=True)\n",
    "\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment = tf.math.softmax(score)\n",
    "alignment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = tf.matmul(alignment, y)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 디코더 입력값에 context 를 붙여서 디코더에 입력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.concat([X_dec, context], axis=-1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lstm_dec(x, initial_state=[h,c])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras.layers.Attention\n",
    "- query : 디코더 입력값\n",
    "- key : 인코더 상태값 (score 계산에 사용)\n",
    "- value : 일반적으로 key 와 동일한 값 (context 계산에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = keras.layers.Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 4, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2 = att([X_dec, y])\n",
    "context2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직접 계산값과 비교 (W 를 적용하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\n",
       "array([[[-0.15611765,  0.1217734 ,  0.16531764],\n",
       "        [-0.15917274,  0.12554456,  0.16847825],\n",
       "        [-0.15341723,  0.11986105,  0.16378854],\n",
       "        [-0.15732676,  0.12845924,  0.1706277 ]],\n",
       "\n",
       "       [[ 0.00454625,  0.03929135, -0.07950398],\n",
       "        [-0.00950378,  0.03603135, -0.03380698],\n",
       "        [ 0.00108905,  0.03290253, -0.08777024],\n",
       "        [-0.01207615,  0.03576973, -0.01779978]]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.nn.softmax(tf.matmul(X_dec, y, transpose_b=True)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\n",
       "array([[[-0.15611765,  0.1217734 ,  0.16531764],\n",
       "        [-0.15917274,  0.12554456,  0.16847825],\n",
       "        [-0.15341723,  0.11986105,  0.16378854],\n",
       "        [-0.15732676,  0.12845924,  0.1706277 ]],\n",
       "\n",
       "       [[ 0.00454625,  0.03929135, -0.07950398],\n",
       "        [-0.00950378,  0.03603135, -0.03380698],\n",
       "        [ 0.00108905,  0.03290253, -0.08777024],\n",
       "        [-0.01207615,  0.03576973, -0.01779978]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras.layers.MultiHeadAttention\n",
    "- Attention is all you Need 논문 (Transformer)\n",
    "<img src='http://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhead = keras.layers.MultiHeadAttention(num_heads=2, key_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 4, 3]), TensorShape([2, 2, 4, 5]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context3, scores = mhead(X_dec, y, return_attention_scores=True)\n",
    "context3.shape, scores.shape # scores -> (batch, mhead, dec, inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 4, 3]), TensorShape([2, 2, 4, 4]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context4, scores = mhead(X_dec, X_dec, return_attention_scores=True)\n",
    "context4.shape, scores.shape # scores -> (batch, mhead, dec, inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최신 언어 딥러닝 모델\n",
    "- transformer : http://jalammar.github.io/illustrated-transformer/\n",
    "- BERT : http://jalammar.github.io/illustrated-bert/\n",
    "- GPT-3 : http://jalammar.github.io/how-gpt3-works-visualizations-animations/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
